{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "NbKFYEbiip31"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "QxrtTob1ip0Y"
   },
   "outputs": [],
   "source": [
    "# Sample text data (documents)\n",
    "docs = [\n",
    "    \"this is a sample document\",\n",
    "    \"this document is a sample\",\n",
    "    \"sample document is simple and short\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "DGvmnEZqipwt"
   },
   "outputs": [],
   "source": [
    "# Preprocess: Tokenize and lowercase\n",
    "def preprocess(text):\n",
    "    return text.lower().split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "R5fx9Vcript-"
   },
   "outputs": [],
   "source": [
    "# Generate n-grams (unigram, bigram, trigram)\n",
    "def generate_ngrams(tokens, n):\n",
    "    return [' '.join(tokens[i:i+n]) for i in range(len(tokens)-n+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "QHqK_WONipna"
   },
   "outputs": [],
   "source": [
    "# Build the corpus with unigrams, bigrams, trigrams\n",
    "def build_corpus(docs):\n",
    "    corpus = []\n",
    "    for doc in docs:\n",
    "        tokens = preprocess(doc)\n",
    "        unigrams = generate_ngrams(tokens, 1)\n",
    "        bigrams = generate_ngrams(tokens, 2)\n",
    "        trigrams = generate_ngrams(tokens, 3)\n",
    "        corpus.append(unigrams + bigrams + trigrams)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "7AwitJPOipcd"
   },
   "outputs": [],
   "source": [
    "# Term Frequency (TF)\n",
    "def compute_tf(corpus):\n",
    "    tf_scores = []\n",
    "    for doc in corpus:\n",
    "        tf = defaultdict(int)\n",
    "        for term in doc:\n",
    "            tf[term] += 1\n",
    "        total_terms = len(doc)\n",
    "        for term in tf:\n",
    "            tf[term] /= total_terms\n",
    "        tf_scores.append(tf)\n",
    "    return tf_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "HEyLptnLipIs"
   },
   "outputs": [],
   "source": [
    "# Inverse Document Frequency (IDF)\n",
    "def compute_idf(corpus):\n",
    "    N = len(corpus)\n",
    "    idf = defaultdict(int)\n",
    "    # Count how many documents contain each term\n",
    "    for doc in corpus:\n",
    "        unique_terms = set(doc)\n",
    "        for term in unique_terms:\n",
    "            idf[term] += 1\n",
    "    # Compute IDF score\n",
    "    for term in idf:\n",
    "        idf[term] = math.log(N / idf[term]) + 1  # Adding 1 to avoid zero division\n",
    "    return idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "CJG9sqK2i91O"
   },
   "outputs": [],
   "source": [
    "# Compute TF-IDF\n",
    "def compute_tfidf(tf_scores, idf_scores):\n",
    "    tfidf = []\n",
    "    for doc_tf in tf_scores:\n",
    "        doc_tfidf = {}\n",
    "        for term, tf in doc_tf.items():\n",
    "            doc_tfidf[term] = tf * idf_scores[term]\n",
    "        tfidf.append(doc_tfidf)\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "jhYQ70TLi9xw"
   },
   "outputs": [],
   "source": [
    "# Run the pipeline\n",
    "corpus = build_corpus(docs)\n",
    "tf_scores = compute_tf(corpus)\n",
    "idf_scores = compute_idf(corpus)\n",
    "tfidf_scores = compute_tfidf(tf_scores, idf_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qFWoPpzHjDlE",
    "outputId": "c0f24dc9-f96a-47cc-fe8d-d288d6721990"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Document 1 TF-IDF:\n",
      "this: 0.1171\n",
      "is: 0.0833\n",
      "a: 0.1171\n",
      "sample: 0.0833\n",
      "document: 0.0833\n",
      "this is: 0.1749\n",
      "is a: 0.1171\n",
      "a sample: 0.1171\n",
      "sample document: 0.1171\n",
      "this is a: 0.1749\n",
      "is a sample: 0.1171\n",
      "a sample document: 0.1749\n",
      "\n",
      "Document 2 TF-IDF:\n",
      "this: 0.1171\n",
      "document: 0.0833\n",
      "is: 0.0833\n",
      "a: 0.1171\n",
      "sample: 0.0833\n",
      "this document: 0.1749\n",
      "document is: 0.1171\n",
      "is a: 0.1171\n",
      "a sample: 0.1171\n",
      "this document is: 0.1749\n",
      "document is a: 0.1749\n",
      "is a sample: 0.1171\n",
      "\n",
      "Document 3 TF-IDF:\n",
      "sample: 0.0667\n",
      "document: 0.0667\n",
      "is: 0.0667\n",
      "simple: 0.1399\n",
      "and: 0.1399\n",
      "short: 0.1399\n",
      "sample document: 0.0937\n",
      "document is: 0.0937\n",
      "is simple: 0.1399\n",
      "simple and: 0.1399\n",
      "and short: 0.1399\n",
      "sample document is: 0.1399\n",
      "document is simple: 0.1399\n",
      "is simple and: 0.1399\n",
      "simple and short: 0.1399\n"
     ]
    }
   ],
   "source": [
    "# Display results\n",
    "for i, doc_tfidf in enumerate(tfidf_scores):\n",
    "    print(f\"\\nDocument {i+1} TF-IDF:\")\n",
    "    for term, score in doc_tfidf.items():\n",
    "        print(f\"{term}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ibOI4WRtjDcO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'a': 0.11712209234234702,\n",
      "  'a sample': 0.11712209234234702,\n",
      "  'a sample document': 0.17488435738900915,\n",
      "  'document': 0.08333333333333333,\n",
      "  'is': 0.08333333333333333,\n",
      "  'is a': 0.11712209234234702,\n",
      "  'is a sample': 0.11712209234234702,\n",
      "  'sample': 0.08333333333333333,\n",
      "  'sample document': 0.11712209234234702,\n",
      "  'this': 0.11712209234234702,\n",
      "  'this is': 0.17488435738900915,\n",
      "  'this is a': 0.17488435738900915},\n",
      " {'a': 0.11712209234234702,\n",
      "  'a sample': 0.11712209234234702,\n",
      "  'document': 0.08333333333333333,\n",
      "  'document is': 0.11712209234234702,\n",
      "  'document is a': 0.17488435738900915,\n",
      "  'is': 0.08333333333333333,\n",
      "  'is a': 0.11712209234234702,\n",
      "  'is a sample': 0.11712209234234702,\n",
      "  'sample': 0.08333333333333333,\n",
      "  'this': 0.11712209234234702,\n",
      "  'this document': 0.17488435738900915,\n",
      "  'this document is': 0.17488435738900915},\n",
      " {'and': 0.13990748591120733,\n",
      "  'and short': 0.13990748591120733,\n",
      "  'document': 0.06666666666666667,\n",
      "  'document is': 0.09369767387387762,\n",
      "  'document is simple': 0.13990748591120733,\n",
      "  'is': 0.06666666666666667,\n",
      "  'is simple': 0.13990748591120733,\n",
      "  'is simple and': 0.13990748591120733,\n",
      "  'sample': 0.06666666666666667,\n",
      "  'sample document': 0.09369767387387762,\n",
      "  'sample document is': 0.13990748591120733,\n",
      "  'short': 0.13990748591120733,\n",
      "  'simple': 0.13990748591120733,\n",
      "  'simple and': 0.13990748591120733,\n",
      "  'simple and short': 0.13990748591120733}]\n"
     ]
    }
   ],
   "source": [
    "import pprint as p\n",
    "p.pprint(tfidf_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['this',\n",
      "  'is',\n",
      "  'a',\n",
      "  'sample',\n",
      "  'document',\n",
      "  'this is',\n",
      "  'is a',\n",
      "  'a sample',\n",
      "  'sample document',\n",
      "  'this is a',\n",
      "  'is a sample',\n",
      "  'a sample document'],\n",
      " ['this',\n",
      "  'document',\n",
      "  'is',\n",
      "  'a',\n",
      "  'sample',\n",
      "  'this document',\n",
      "  'document is',\n",
      "  'is a',\n",
      "  'a sample',\n",
      "  'this document is',\n",
      "  'document is a',\n",
      "  'is a sample'],\n",
      " ['sample',\n",
      "  'document',\n",
      "  'is',\n",
      "  'simple',\n",
      "  'and',\n",
      "  'short',\n",
      "  'sample document',\n",
      "  'document is',\n",
      "  'is simple',\n",
      "  'simple and',\n",
      "  'and short',\n",
      "  'sample document is',\n",
      "  'document is simple',\n",
      "  'is simple and',\n",
      "  'simple and short']]\n"
     ]
    }
   ],
   "source": [
    "p.pprint(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
